\documentclass[12pt]{beamer}
\usepackage{../latex-sty/mypres}
\expandafter\def\expandafter\insertshorttitle\expandafter{%
  \insertshorttitle\hfill%
  \insertframenumber\,/\,\inserttotalframenumber}
\usefonttheme[onlymath]{serif}
\usepackage{listings}
\lstset{language=Python}
\usepackage[normalem]{ulem}
\newcommand{\blambda}{\boldsymbol{\lambda}}
\newcommand{\bmu}{\boldsymbol{\mu}}

\begin{document}
\title[Введение в оптимизацию]{Введение в теорию \\ методов оптимизации}

\author[А. Катруца]{Aлександр Катруца \\[0.9cm] 
\includegraphics[scale=0.5]{logo_sirius}}

\date{Сочи 2017}
\begin{frame}
\maketitle
\end{frame}

\begin{frame}{Введение}

\begin{itemize}
\item Что такое методы оптимизации?
\item Какой математический аппарат используется?
\item Как развивалась теория методов оптимизации?
\item Какие главные результаты?
\end{itemize}

\end{frame}

\begin{frame}{Обозначения и типы задач}
\begin{equation*}
\begin{split}
& \min f(x)\\
\text{s.t. } & x \in X \subseteq \bbR^n
\end{split}
\end{equation*}

\begin{itemize}
\item Глобальный vs. локальный минимум
\item Условная vs.безусловная задача
\item Непрерывная vs. дискретная задача
\item Детерминированная vs. стохастическая задача
\end{itemize}
\end{frame}

\begin{frame}{Как сравнивать методы оптимизации?}
\begin{itemize}
\item Теоретическая сложность~--- об этом ниже
\item Масштабируемость
\item Время работы
\item Простота понимания и реализации
\end{itemize}
\end{frame}


\begin{frame}[fragile]{Общая схема}
Математически:
\begin{itemize}
\item Поиск направления $h_k$, чаще всего это направление убывания
\item Выбор шага $\alpha_k$, такого что $f(x_k + \alpha_k h_k) < f(x_k)$
\item Проверка критерия остановки
\end{itemize}

Алгоритмически:
\begin{lstlisting}[language=Python]
while (True):
    h = FindDirection(...)
    alpha = FindStepSize(...)
    x = x + alpha * h
    if StopCriterion(...):
    	break
\end{lstlisting}

\end{frame}

\begin{frame}{Методы первого порядка}
Идея: помимо значения функции в точке, использовать значение первой производной.

\begin{itemize}
\item Градиентный спуск
\item Mетод сопряжённых градиентов
\item Квазиньютоновские методы
\end{itemize}

\end{frame}

\begin{frame}{Методы второго порядка}

Идея: помимо значения функции в точке и значения первой производной использовать значения {\color{red}{второй}} производной в точке.

\begin{itemize}
\item Метод Ньютона
\end{itemize}

\end{frame}

\begin{frame}{Теория двойственности: идея}
\vspace{-2mm}
\begin{block}{Общий принцип}
Полезно иметь несколько взглядов на одну сущность
\end{block}
{\footnotesize
Например:
\vspace{-1mm}
\begin{itemize}
\item множество: перечисление элементов vs. задание ограничений на элементы
\item функция: табличное vs. аналитическое определение
\item задачи: прямое решение vs. переформулировка или решение вспомогательной задачи
\item связь между эллиптическими кривыми и теорией чисел: великая теорема Ферма, криптография, etc
\end{itemize}
}
\vspace{-3mm}
\begin{block}{Двойственность в оптимизации}
\scriptsize
Построение задачи, связанной с данной, которая
\begin{itemize}
\vspace{-1mm}
\item всегда решается легко не зависимо от сложности решения исходной 
\vspace{-1mm}
\item даёт нижнюю оценку на оптимальное значение целевой функции исходной задачи
\end{itemize}
\end{block}
\end{frame}

\begin{frame}{Теория двойственности: конкретика}
\small
\vspace{-2mm}
\begin{block}{Задача}
\vspace{-5mm}
\begin{equation*}
\begin{split}
& \min\limits_{x \in \mathcal{D}} f(x) = p^*\\
\text{s.t. } & g_i(x) = 0, \; i = 1,\ldots,m\\
& h_j(x) \leq 0, \; j = 1,\ldots, p
\end{split}
\end{equation*}
\end{block}

\begin{block}{Лагранжиан}
\vspace{-2mm}
\begin{equation*}
L(x, \blambda, \bmu) = f(x) + \sum\limits_{i=1}^m\lambda_i g_i(x) + \sum\limits_{j=1}^p \mu_j h_j(x)
\vspace{-2mm}
\end{equation*}
\end{block}

\begin{block}{Двойственные переменные}
Вектора $\bmu$ и $\blambda$ называются двойственными переменными.
\end{block}

\begin{block}{Двойственная функция}
Функция $g(\bmu, \blambda) = \inf\limits_{x\in \mathcal{D}} L(x, \blambda, \bmu)$ называется двойственной функцией Лагранжа.
\end{block}

\end{frame}

\begin{frame}{Свойства двойственной функции}
\small
\vspace{-2mm}
\begin{block}{Вогнутость}
Двойственная функция является {\color{red}{вогнутой}} как инфимум аффинных функций по $(\bmu, \blambda)$ вне зависимости от того, является ли исходная задача выпуклой.
\end{block}

\begin{block}{Нижняя граница}
Для любого $\blambda$ и для $\bmu \geq 0$ выполнено $g(\bmu, \blambda) \leq p^*$.
\end{block}

\begin{block}{Двойственная задача}
\vspace{-5mm}
\begin{equation*}
\begin{split}
& \max g(\bmu, \blambda) = d^*\\
\text{s.t. } & \bmu \geq 0
\end{split}
\end{equation*}
\end{block}

\begin{block}{Зачем?}
\begin{itemize}
\vspace{-2mm}
\item Двойственная задача выпукла независимо от того, выпукла ли прямая
\vspace{-3mm}
\item Нижняя оценка \textbf{может} достигаться
\end{itemize}
\end{block}
\end{frame}


\begin{frame}{Элементы теории сложности}

\begin{block}{Главный вопрос}
\begin{center}
\sout{Быть или не быть?} 

Какой метод оптимизации лучше для данной задачи?
\end{center}
\end{block}

Возможные ответы:
\begin{itemize}
\item экспериментально сравнить несколько методов
\item определить к какому {\color{red}{классу}} задач относится данная и использовать наилучший метод для этого класса задач
\end{itemize}

\end{frame}

\begin{frame}{Оптимальные методы}

\end{frame}

\begin{frame}{Заключение}

\begin{itemize}
\item Зачем нужны методы оптимизации?
\item Итеративная схема
\item Классификация методов и их анализ
\item Теория двойственности
\item Элементы теории сложности
\end{itemize}
\end{frame}

\end{document}